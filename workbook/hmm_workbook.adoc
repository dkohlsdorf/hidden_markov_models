= Hidden Markov Models                              
Daniel Kohlsdorf (c) 2019                                      
:sectnums:                                                          
:toc:                                                               
:toclevels: 4                                                       
:toc-title: Content                                                                                    
:description: Example AsciiDoc document                             
:keywords: AsciiDoc                                                 
:imagesdir: ./img                                                   

== Foreword

This short tutorial is a practical guide to probabilistic modeling
of sequential data by implementing hidden Markov models. At the end of this tutorial readers will be able to model sequential data from various
applications including: biological sequences, text, speech or gesture.

Readers are expected to be intermediate python programmers. Cython
knowledge will help, too. I decided to use python since it is
one of the most common used language in data science and 
cython to speed up some of the heavy lifting required by HMMs.
However, if you don't care about speed the reader can also 
implement everything in pure python. The sections where
the reader could benefit from cython's speed are highlighted.

I provide the practical part of the book in the form of a test suit. Readers are expected to write the actual code to make the tests happen.
One possible solution code can be found in this github repository.

== Introduction to Sequence Modeling
Before we start modeling sequences, we need to understand
the type of data we are dealing with. Chapter 2.1 will introduce
different forms of sequence data while Chapter 2.2 will introduce 
the concept of timewarp and alignment. 

=== Sequence Data

Classically there are two types of sequences: catgeorical sequences and time series. Categorical sequences are sequences of discrete symbols
such as sequences of letters to form words, sequences of words to form text and sequences of bases that form DNA. Time series are numeric sequences of scalar numbers or vectors.

==== Text
==== DNA
==== Sensors
==== Speech

=== Alignment

=== Problems
==== Recognition
==== Clustering
==== Segmentation

== Short Probability Primer

=== Probabilities And Bayes Theorem

=== The Multinomial Distribution

=== The Normal Distribution

== Numerically Stable Probabilities

=== Log Probabilites

=== Implementing Multiplication and Addition

== Markov Chains

=== Modeling Sequences with Markov Chains

=== Implementing Probability Calculations with Markov Chains

=== Applications in Text Processing

== Hidden Markov Models Basics

=== Modeling unobservable Markov Chains with HMMs

=== Implementing A Hidden Markov Model

=== Applications in Gesture Recognition

== The Viterbi Algorithm

=== Viterbi Decoding and Backtracking

== The Forward / Backward Algorithm

== Baum Welch Estimation 

